{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy.testing as test\n",
    "import re\n",
    "import warnings \n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Normalizer, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin) :    \n",
    "    def __init__(self, columns):\n",
    "        self.columns=columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NameEncoder(BaseEstimator, TransformerMixin) :    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        nameDict={1 : ['Mr'], \n",
    "          2 : ['Miss', 'Mlle'],\n",
    "          3 : ['Mrs', 'Mme'],\n",
    "          4 : ['Dr'],\n",
    "          5 : ['Col', 'Major', 'Capt'],\n",
    "          6 : ['Countess', 'Sir', 'Lady', 'Don'],\n",
    "          7 : ['Master', 'Jonkheer']\n",
    "        }\n",
    "        x = np.array( [re.split(',|\\.', p)[1].strip() for p in X] )\n",
    "        x1= np.zeros(x.shape[0])\n",
    "\n",
    "        for key in nameDict:\n",
    "            for f in nameDict[key]:   \n",
    "                idx = 0\n",
    "                for t in x:\n",
    "                    if (t == f):\n",
    "                        x1[idx]=key\n",
    "                    idx = idx + 1\n",
    "                        \n",
    "        return x1.astype(int).reshape(-1,1)\n",
    "    @staticmethod\n",
    "    def test():\n",
    "        nameEncoder = NameEncoder()\n",
    "        res = nameEncoder.fit_transform(np.array([['p, Mr Jimmy'], ['x, Mrs. Smith'], ['y, Mr. Smith']]))\n",
    "#         test.assert_array_equal(res, [[0],[2],[3]])\n",
    "        print(res)\n",
    "       \n",
    "# ne = NameEncoder()\n",
    "# x = DataFrameSelector('Name').fit_transform(df)\n",
    "# f = ne.fit_transform(x)\n",
    "# # print(f[0:20], f.shape)\n",
    "# # print(df['Name'][0:20])\n",
    "\n",
    "# mu = make_union(\n",
    "#     make_pipeline(DataFrameSelector('Name'), NameEncoder()),\n",
    "#     make_pipeline(DataFrameSelector(['Age']), StandardScaler()) ) # union\n",
    "\n",
    "# x = mu.fit_transform(df)\n",
    "\n",
    "# np.unique(x[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age imputer expects an 2D array having on the first column\n",
    "# the encoded name 0,1,2,3,4 and on the second column the age\n",
    "class AgeImputer(BaseEstimator, TransformerMixin) :        \n",
    "    # fit will calculate the averages per encoded name\n",
    "    def fit(self, X, y=None):\n",
    "        self.titleAgeDictionary = {}\n",
    "        for key in np.arange(0, 8):\n",
    "            try: # just to make sure for unit tests add a try/catch\n",
    "                self.titleAgeDictionary[key] = np.nanmedian(X[X[:,0] == key, 1])\n",
    "                if (key == 2):\n",
    "                    self.titleAgeDictionary[key]=9\n",
    "            except:\n",
    "                print('Fault')\n",
    "                pass\n",
    "        print(self.titleAgeDictionary)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):        \n",
    "        for key in self.titleAgeDictionary.keys():\n",
    "            X[(X[:,0] == key) & (np.isnan(X[:,1])),1]=self.titleAgeDictionary[key]\n",
    "        return X\n",
    "\n",
    "    def test(self):\n",
    "        X=np.array([[1,12],\n",
    "          [2,12],\n",
    "          [1, np.NaN]])\n",
    "        res = self.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5373870054192047, 1: 0.020727176659648322, 2: 9, 3: 0.36516706249935255, 4: 1.1573787999306722, 5: 1.8118145830261103, 6: 1.2607107656825836, 7: -1.7703602297068137}\n",
      "(891, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 1., 2.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataframe\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "def hasCabin(x):\n",
    "     return np.apply_along_axis(lambda t : 0 if ( t != t) else 1 ,arr=x ,axis=1)\n",
    "\n",
    "y = df['Survived'].values\n",
    "\n",
    "df.drop(labels=['Survived'], axis=1, inplace=True)\n",
    "\n",
    "pipeline = make_column_transformer(\n",
    "    (['Name', 'Age'], make_pipeline(\n",
    "                        make_union(\n",
    "                            make_pipeline(DataFrameSelector('Name'), NameEncoder()),\n",
    "                            make_pipeline(DataFrameSelector(['Age'])\n",
    "                                          , StandardScaler()\n",
    "                                         ) \n",
    "                        ), # union\n",
    "                       AgeImputer(), \n",
    "                       make_column_transformer(([0], OneHotEncoder(sparse=False)), remainder='passthrough' )\n",
    "                    ) # pipeline age\n",
    "    ), #tuple\n",
    "    (['Sex', 'Pclass'], OneHotEncoder(sparse=False)),\n",
    "    (['Embarked'], make_pipeline( SimpleImputer( strategy='constant', fill_value='S' ), OneHotEncoder(sparse=False))), \n",
    "    (['Fare'], make_pipeline( SimpleImputer(strategy='mean'), FunctionTransformer( lambda x : np.log2(x, where=x>0)), StandardScaler() )),\n",
    "#     (['Cabin'], make_pipeline( FunctionTransformer(hasCabin, validate=False), OneHotEncoder(sparse=False)) ), \n",
    "    (['SibSp', 'Parch'], make_pipeline(DataFrameSelector(['SibSp','Parch']), \n",
    "                                       FunctionTransformer(lambda x : (x[:,0] + x[:,1]).reshape(-1,1)))), \n",
    "    (['SibSp', 'Parch'], make_pipeline(DataFrameSelector(['SibSp','Parch']), \n",
    "                                       FunctionTransformer(lambda x : (x[:,0] + x[:,1] == 0).reshape(-1,1)))), \n",
    "    (['Age'], make_pipeline( FunctionTransformer(lambda x : x < 14, validate=False), OneHotEncoder(sparse=False)) ), \n",
    "    (['SibSp', 'Parch'], 'passthrough'),    \n",
    "    (['PassengerId', 'Cabin'], 'drop'),\n",
    "    )\n",
    "x = pipeline.fit_transform(df)\n",
    "\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... fitting\n",
      ".... predicting\n",
      "Accuracy Score= 0.8715083798882681\n",
      "Precision Score= 0.8253968253968254\n",
      "Recall Score= 0.8125\n",
      "F1 Score= 0.8188976377952756\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr =LogisticRegression();\n",
    "\n",
    "# forest_cv = GridSearchCV(estimator=lr,  param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, cv=5) \n",
    "# print(forest_cv.get_params())\n",
    "# s = cross_val_score(lr, x, y, scoring='neg_mean_squared_error', cv=4)\n",
    "# scores=np.log(-s)\n",
    "# print(scores)\n",
    "# print('Mean=', scores.mean())\n",
    "# print('Standard Dev=', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "# check by getting 80/20\n",
    "num_train=int(x.shape[0]*0.8)\n",
    "x_train=x[:num_train,:]\n",
    "y_train=y[:num_train]\n",
    "\n",
    "x_test=x[num_train:,:]\n",
    "y_test=y[num_train:]\n",
    "\n",
    "print('.... fitting')\n",
    "lr.fit(x_train, y_train)\n",
    "print('.... predicting')\n",
    "\n",
    "# print(forest_cv.best_params_) \n",
    "\n",
    "y_predict = lr.predict(x_test)\n",
    "\n",
    "# # print(y_predict[:20])\n",
    "# # print(y_test[:20])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "# confusion_matrix(y_test, y_predict)\n",
    "prec_score = precision_score(y_test, y_predict)\n",
    "rec_score = recall_score(y_test, y_predict)\n",
    "acc_score = accuracy_score(y_test, y_predict)\n",
    "f1_sc = f1_score(y_test, y_predict)\n",
    "print(\"Accuracy Score=\", acc_score)\n",
    "print(\"Precision Score=\", prec_score)\n",
    "print(\"Recall Score=\", rec_score)\n",
    "print(\"F1 Score=\", f1_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "x1 = pipeline.transform(df)\n",
    "\n",
    "y_predict = lr.predict(x1)\n",
    "\n",
    "kaggle = pd.DataFrame({'PassengerId': df['PassengerId'], 'Survived': y_predict})\n",
    "\n",
    "# save to csv\n",
    "kaggle.to_csv('titanic_pred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "d = DataFrameSelector(['Name'])\n",
    "x1 = d.fit_transform(df)\n",
    "# x1.reshape(-1,1)\n",
    "# x1=np.array(['Ala', 'Bala'])\n",
    "\n",
    "def f(p) :    \n",
    "    return re.split(',|\\.', p)[1].strip()\n",
    "x = np.array( [re.split(',|\\.', p)[1].strip() for p in x1[:,0]] )\n",
    "x\n",
    "# x = df['Name'].str.extract(r',(.+)\\.')\n",
    "# x\n",
    "# nameDict={'Mr' : ['Mr'], \n",
    "#           'Miss' : ['Miss', 'Mlle'],\n",
    "#           'Mrs' : ['Mrs', 'Mme'],\n",
    "#           'Dr' : ['Dr'],\n",
    "#           'Col' : ['Col', 'Major', 'Capt'],\n",
    "#           'Sir' : ['Countess', 'Sir', 'Lady', 'Don'],\n",
    "#           'Master' : ['Master', 'Jonkheer']\n",
    "#          }\n",
    "\n",
    "\n",
    "# for f in nameDict:\n",
    "#     print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(['Mr', 'Miss', 'Moss', 'Mr', 'Pula'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "l = LabelEncoder()\n",
    "\n",
    "l.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[(df['Name'].str.contains('Master')) & (df['Parch']>0)]\n",
    "x = df[(df['Parch']>0)]\n",
    "x['Age'].median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
